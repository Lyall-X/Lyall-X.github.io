---
layout: post
title: Kubernetes
categories: 云原生
description: kubernetes
keywords: kubernetes, k8s
---

## K8S

### K8s背景

K8S前世今生

docker等端口映射复杂，引入了资源管理器

* Apache Mesos：分布式资源管理框架
* docker swarm：轻量，
* K8S：靠山谷歌，10年容器化基础架构  borg   GO 语言

K8S特点：

        轻量级：消耗资源小

        开源

        弹性伸缩

        负载均衡：IPVS

---

kubeadm可以快速部署kubernets集群，使用二进制部署，创建方法：

```
#创建一个master节点
Kubeadm init
将一个node节点加入到当前集群中
kubeadm join <Master节点的ip和端口>
```

K8s有三套网络：

1. node网络：节点网络
2. Pod网络：容器网络
3. Service网络：集群网络

10：ipc私有地址；4：机房；7：不同的项目业务；

K8s四组概念：

* Pod/Pod控制器
* Name/Namespace
* Label/Label选择器
* Serice/Ingress

---

Pod:

* Pod是k8s里能够被运行的最小逻辑单元(原子单元)
* 1个Pod里面可以运行多个容器，他们共享UTS + NET + IPC 名称空间；但是容器会隔离这些
* 一个Pod运行多个容器，又叫：边车(SideCar)模式

Pod控制器：

* Pod控制器是Pod启动的一种模版，用来保证K8s里启动的Pod按照人们预期运行(副本数，生命周期，健康状态检查...)
* K8s提供众多Pod控制器，常用的有：
  * Deployment 部署
  * DaemonSet
  * ReplicaSet 
  * StatefulSet 管理由状态Pod
  * Job 管理任务
  * Cronjob 管理定时任务

Name：

* 由于k8s内部，使用资源来定义每种逻辑概念(功能)，故每种资源都应有其名称
* 资源有api版本类别，元数据，定义清单，状态等配置信息
* 名称通常定义在资源的元数据信息里

Namespace:

* 名称空间：需要一种能够隔离k8s内各种资源的方法
* 可以理解为k8s内部的虚拟集群组
* 不同名称空间内部的资源，名称可以相同；相同名称空间内的同种资源不能相同
* 合理的使用k8s的名称空间，能更好的管理k8s里的服务
* 默认名称空间：default；kube-system；kube-public
* 查询k8s里特定的资源，要带上相应的名称空间

Label：

* 便于分类管理各类资源对象
* 标签与资源是多对多
* 一个资源可以有多个标签
* 标签：key=value
* 与标签类似，还有 注解

Label选择器：

* 可以使用标签选择器过滤制定标签
* 基于等值关系(等于，不等于)和基于集合关系(属于，不属于，存在)
* 许多资源支持内嵌标签选择器字段
  * matchLabels
  * matchExpressions

Service:

* 每个pod都会被分配一个单独的ip地址，但这个ip会随着pod销毁而消失
* service(服务)就是用来解决这个问题
* 一个Service看作一组提供相同服务的Pod的对外访问接口
* Service作用于哪些Pod是通过标签选择器来定义的

Ingress：

* Ingress是k8s集群里工作在os网络参考模型下，第七层的应用，对外暴露的借口
* Service只能进行L4流量调度，表现形式是ip + port
* Ingress则可以调度不同的业务域，不同url访问路径的业务流量

---

### K8S组件

核心组件：

* 配置存储中心 ->etcd服务
* 主控 master节点
  * kube-apiservice服务
  * kube-controller-manager服务
  * kebe-scheduler服务

* 运算 node节点
  * kube-kubelet服务
  * kube-proxy服务

* CLI客户端
  * kubectl：命令行工具

核心附件：

* CNI网络插件 -> flannel/calico
  * 服务发现用插件 -> coredns
  * 服务暴露用插件 -> traefik
  * GUI管理插件 -> Dashboard

核心组件详情：

请求 -> apiserver -> controller-manager -> scheduler

apiserver：k8s大脑

* 提供了集群管理的REST API接口(包括鉴权，数据校验及集群状态变更)
* 负责其他模块之间的数据交互，承担通信枢纽功能
* 是资源配额控制的入口
* 提供完备的集群安全机制

controller-manager：

* 由控制器组成，通过apiserver监控整个集群的状态，并确保集群处于预期的工作状态

scheduler：

* 主要功能是接受调度pod到适合的运算节点上
* 预算策略 predict
* 优选策略 priorities

Kubelet：真正工作节点的工作

* 定时从某个地方获取节点上pod的期望状态，并调用docker借口以达到这个状态
* 定时汇报当前节点状态给apiserver，以供调度的时候使用
* 镜像和容器的清理工作，保证节点上镜像不会占满磁盘空间

kube-proxy：

* 是k8s在每个节点上运行网络代理；service资源的载体
* 建立了pod网络和集群网络的关系(clusterip -> podip)
* 流量调度模式：Ipvs
* 负责建立和删除包括更新调度规则，通知apiserver哪里获取其他kube-proxy的调度规则变化来更新自己的

---

### K8s架构

![截屏2020-11-15_下午5-04-59.png](\images\posts\k8s\截屏2020-11-15_下午5-04-59.png)

项目k8s架构：

![截屏2020-11-15_下午5-05-35.png](\images\posts\k8s\截屏2020-11-15_下午5-05-35.png)

常见的k8s部署方式

1. Minikube 单节点微型k8s (仅供学习，预览使用)
   1. [https://kubernetes.io/docs/tutorials/hello-minikube/](https://kubernetes.io/docs/tutorials/hello-minikube/)

2. 二进制安装部署 (生产首选，新手推荐)
3. 使用 kubeadmin 进行部署，k8s的部署工具，跑在k8s里 (相对简单，熟手推荐)

------

## 微服务

### 微服务介绍

软件架构：

* 业务需求
* 成本
* 可扩展性
* 技术栈
* 组织架构
* 可维护性

单体架构：

* 功能，业务集中在一个发布包中，部署运行在同一个进程
* 优势：易于开发，易于测试，易于部署，易于水平伸缩
* 劣势：臃肿，可扩展性差

---

微服务：

* 使用 一套小服务来开发单个应用的方式，每个服务运行在独立的进程，一般采用轻量级的通讯机制互联，并且能自动化部署

微服务特征：

* 单一职责(邮件服务，登陆服务)
* 轻量级通信(与平台无关，与语言无关)
* 隔离性
* 有自己的数据
* 技术的多样性

微服务思考问题：

* 微服务如何通讯？
* 微服务如何发现彼此？
* 微服务怎样部署？更新？扩容？

---

微服务通讯：通讯模式与通信协议两方面分析

通讯模式：

* 一对多
  * 发布订阅/发布异步响应

通信协议：

* REST API
* RPC：
  * dubbo
  * grpc
  * thrift

* MQ(消息队列)

---

### RPC框架

* I/O(长短连接)，线程调度模型(单多线程)
* 序列化方式
  * 可读的http，xml
  * 二进制，fastjson

* 多语言支持
* 服务治理
  * 服务发现

流行的RPC框架：

* Dubbo/Dubbox：
* Motan
* Thrift
* Grpc

---

### Dubbo

![e28c3ceb2fe83e040d06fc45aa7db71f.png](\images\posts\k8s\e28c3ceb2fe83e040d06fc45aa7db71f.png)

蓝色箭头：服务初始化的时候做的

实线同步，虚线异步

---

![e75fb61cc6177670266ffd65b4a61ce0.png](\images\posts\k8s\e75fb61cc6177670266ffd65b4a61ce0.png)

---

### 服务编排

* Mesos
* Docker Swarm
* Kubernetes

------

## kubernetes组件介绍

IAAS：Infrastructure as a Service 基础设施即服务；阿里云

PAAS：platform as a service平台即服务；新浪云

SAAS：Software as a Service软件设施即服务；office 365

docker 网络转换NAT模式，需要借助防火墙

docker容器过多，端口一系列映射转换起来太麻烦 -> 资源管理器 k8s

资源管理器：

* Apache MESOS：分布式资源管理框架   2019-5  Twitter  》 Kubernetes
* docker SWARM：docker swarm init 轻量，但是功能太少；2019-07   阿里云宣布  Docker Swarm  剔除
* Kubernetes：Google 10年容器化基础架构  borg   GO 语言   Borg
  * 特点：
  * 轻量级：消耗资源小
  * 开源
  * 弹性伸缩
  * 负载均衡：IPVS

服务分类:

* 有状态服务：DBMS
* 无状态服务：LVS APACHE

---

介绍说明：

* 发展历史
* K8S组件说明，框架
* K8S关键字含义

基础概念：

* Pod概念：最小封装集合；控制器类型
* K8S 网络通讯模式

Kubernetes安装：

* 构建 K8S 集群

资源清单：

* 资源
* 掌握资源清单的语法   
* 编写 Pod 
* 掌握 Pod 的生命周期

Pod 控制器：

* 掌握各种控制器的特点以及使用定义方式

服务发现：

* 掌握 SVC 原理及其构建方式

存储：更适合无状态服务

* 掌握多种存储类型的特点
* 并且能够在不同环境中选择合适的存储方案（有自己的见解）

调度器：可以根据需求，把pod放在不同的节点

* 掌握调度器原理 
* 能够根据要求把Pod 定义到想要的节点运行

安全：

* 集群的认证
* 鉴权   
* 访问控制 原理及其流程

HELM：类似于 Linux yum 

* 掌握 HELM 原理   
* HELM 模板自定义
* HELM 部署一些常用插件

运维：

* 修改Kubeadm 达到证书可用期限为 10年    
* 能够构建高可用的 Kubernetes 集群

---

**组件说明：**

高可用集群副本数据最好是 >= 3 奇数个

**Borg架构：**

![fafc811f6126c1ead7505a191e63ba2b.png](\images\posts\k8s\fafc811f6126c1ead7505a191e63ba2b.png)

* BorgMaster：请求分发
* Borglet：控制容器运行
* config file：集群管理终端
* scheduler：调度器，请求写入到Paxos中
* Paxos：键值对数据库

**Kubernetes架构图：C/S架构**

![bdea869f9fdb128644a7bc65f9fffa56.png](\images\posts\k8s\bdea869f9fdb128644a7bc65f9fffa56.png)

maste组件：

* scheduler：调度器，负责介绍任务，选择合适的节点进行分配任务；将请求写入api server，然后api server将请求写入 etcd数据库中
* RC：replication controller 控制器，维持副本期望数目
* api server：所有服务访问统一入口
* etcd：类似于Paxos，采用go编写，持久化方案；键值对数据库，储存K8S集群所有重要信息（持久化）
  *  v2版会将数据写入到内存Memory中，v3版引入本地卷的持久化操作
  *  k8s v1.11前使用v2，之后使用的v3，推荐使用v3

node节点：

* kubelet： C(container)R(runtime)L(interface)直接跟容器引擎交互实现容器的生命周期管理
* kube proxy：负责写入规则至 IPTABLES、IPVS 实现服务映射访问的
* container：容器引擎(docker)

其他插件：

* CoreDNS：可以为集群中的SVC创建一个域名IP的对应关系解析
* Dashboard：给 K8S 集群提供一个 B/S 结构访问体系
* Ingress controller：官方只能实现四层代理，INGRESS 可以实现七层代理
* Federation：提供一个可以跨集群中心多K8S统一管理功能
* Promethus：提供K8S集群的监控能力
* ELK：提供 K8S 集群日志统一分析介入平台

**etcd架构图：**

![5d0baf8ffe3f2069b40241e9c418ce55.png](\images\posts\k8s\5d0baf8ffe3f2069b40241e9c418ce55.png)

* 采用http协议，进行c/s构建的服务；K8S也是采用http协议，进行C/S开发
* Raft：存储所有的读写信息
* WAL：预写日志
* Store：本地磁盘存储

------

## Pod的概念，网络通讯方式

#### Pod的概念

* 自主式 Pod
  * 死亡无法清除
  * 死亡无法拉起

* 控制器管理 Pod

Pod中容器实现网络互通：

* 每个Pod都会起一个pause容器
* 每个容器公用pause网络栈，共享存储卷
  * 直接localhost就可以互相访问

* 因为共享网络，同一个pod里端口不能一样

---

#### 控制器

* ReplicationController： 控制期望值，不足则自动创建新的 Pod 来替代；异常多出来的容器也会自动回收
* ReplicaSet： 新版本的 Kubernetes 中建议使用 ReplicaSet 来取代RC； 支持集合式的 selector可以为集合打标签，直接根据标签删除等操作
* Deployment： 建议使用 Deployment 来自动管理
  * 定义 Deployment 来创建 Pod 和 ReplicaSet
  * 滚动升级和回滚应用
  * 扩容和缩容
  * 暂停和继续 Deployment

![74f0dffaceba2ac298d5cc41a74a196a.png](\images\posts\k8s\74f0dffaceba2ac298d5cc41a74a196a.png)

Horizontal Pod Autoscaling：HPA

* 根据 Pod

StatefulSet： 为了解决有状态服务的问题

* 稳定的持久化存储：新的pod会用旧的pod数据
* 稳定的网络标志，主机名不变
* 有序部署，
* 有序收缩，有序删除

DaemonSet：

* 确保全部（或者一些）Node 上运行一个 Pod 的副本
* 运行集群存储 daemon，例如在每个 Node 上运行 glusterd、ceph。
* 在每个 Node 上运行日志收集 daemon，例如fluentd、logstash。
* 在每个 Node 上运行监控 daemon，例如 Prometheus Node Exporter

Job：负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束

* 在给定时间点只运行一次
* 周期性地在给定时间点运行

---

#### 服务发现

![f126fc789131cb712d3fa042f6bae322.png](\images\posts\k8s\f126fc789131cb712d3fa042f6bae322.png)

网络通讯模式：

* Kubernetes 的网络模型假定了所有 Pod 都在一个可以直接连通的扁平的网络空间中
* 这在
* 而在私有云里搭建 Kubernetes 集群，就不能假定这个网络已经存在了。我们需要自己实现这

![a3946dab6370d102d505a0c0e016f3a9.png](\images\posts\k8s\a3946dab6370d102d505a0c0e016f3a9.png)

![2c4dc1d59b1a942d92840ab45640d6be.png](\images\posts\k8s\2c4dc1d59b1a942d92840ab45640d6be.png)

------

### Yaml

资源清单：

* 缩紧不允许使用tab，只允许使用空格

* 缩紧的空格数目不重要，只要相同层级的元素左侧对齐即可

* 标示注释

支持数据类型：

* 对象：键值对集合
* 数据
* 纯量

------

## K8s安装

安装虚拟机，下载iso镜像，修改vmwar的网络nat设置，[绑定虚拟机的静态ip](https://blog.csdn.net/get_set/article/details/50707553)，安装常用的软件

```
1.安装epel-release
# yum install -y epel-release
2.安装必要工具
# yum install -y wget net-tools telnet tree nmap sysstat lrzsz dos2unix bind-utils
```

### 安装部署

1. 准备5台2c/2g/50g虚机，使用10.4.7.0/24网络
2. 预装Centos 7.6操作系统，做好基础优化
3. 安装部署 bind9，部署自建DNS系统
4. 准备自签证书环境
5. 安装部署Docker环境，部署Harbor私有仓库

---

dns默认监听53端口

forwarders { 10.4.7.254; }; #上一层DNS地址(网关或公网DNS)

recursion yes;采用递归算法进行dns查询

主机域：host.com

业务域：od.com

dockerhub 要选择 1.7.6及其以上的版本，就版本越权漏洞

---

证书时间统一为10年,不怕过期

证书类型

client certificate：客户端使用，用于服务端认证客户端,例如etcdctl、etcd proxy、fleetctl、docker客户端

server certificate：服务端使用，客户端以此验证服务端身份,例如docker服务端、kube-apiserver

peer certificate：双向证书，用于etcd集群成员间通信

需要将所有可能用来部署etcd的机器,都加入到hosts列表中

否则后期重新加入不在列表中的机器,需要更换所有etcd服务的证书

不支持网段，只能用ip

---

etcd的启动参数：

--name #节点名字

--listen-peer-urls #监听其他节点所用的地址

--listen-client-urls #监听etcd客户端的地址

--initial-advertise-peer-urls #与其他节点交互信息的地址

--advertise-client-urls #与etcd客户端交互信息的地址

---

使用RBAC鉴权规则,创建了一个ClusterRoleBinding的资源

此资源中定义了一个user叫k8s-node

给k8s-node用户绑定了角色ClusterRole,角色名为system:node

使这个用户具有成为集群运算节点角色的权限

由于这个用户名,同时也是kubeconfig中指定的用户,

所以通过kubeconfig配置启动的kubelet节点,就能够成为node节点

---

### 配置文件

```y
#test-pod
apiVersion: v1 #指定api版本，此值必须在kubectl apiversion中   
kind: Pod #指定创建资源的角色/类型   
metadata: #资源的元数据/属性   
  name: test-pod #资源的名字，在同一个namespace中必须唯一   
  labels: #设定资源的标签
    k8s-app: apache   
    version: v1   
    kubernetes.io/cluster-service: "true"   
  annotations:            #自定义注解列表   
    - name: String        #自定义注解名字   
spec: #specification of the resource content 指定该资源的内容   
  restartPolicy: Always #表明该容器一直运行，默认k8s的策略，在此容器退出后，会立即创建一个相同的容器   
  nodeSelector:     #节点选择，先给主机打标签kubectl label nodes kube-node1 zone=node1   
    zone: node1   
  containers:   
  - name: test-pod #容器的名字   
    image: 10.192.21.18:5000/test/chat:latest #容器使用的镜像地址   
    imagePullPolicy: Never #三个选择Always、Never、IfNotPresent，每次启动时检查和更新（从registery）images的策略，
                           # Always，每次都检查
                           # Never，每次都不检查（不管本地是否有）
                           # IfNotPresent，如果本地有就不检查，如果没有就拉取
    command: ['sh'] #启动容器的运行命令，将覆盖容器中的Entrypoint,对应Dockefile中的ENTRYPOINT   
    args: ["$(str)"] #启动容器的命令参数，对应Dockerfile中CMD参数   
    env: #指定容器中的环境变量   
    - name: str #变量的名字   
      value: "/etc/run.sh" #变量的值   
    resources: #资源管理
      requests: #容器运行时，最低资源需求，也就是说最少需要多少资源容器才能正常运行   
        cpu: 0.1 #CPU资源（核数），两种方式，浮点数或者是整数+m，0.1=100m，最少值为0.001核（1m）
        memory: 32Mi #内存使用量   
      limits: #资源限制   
        cpu: 0.5   
        memory: 1000Mi   
    ports:   
    - containerPort: 80 #容器开发对外的端口
      name: httpd  #名称
      protocol: TCP   
    livenessProbe: #pod内容器健康检查的设置
      httpGet: #通过httpget检查健康，返回200-399之间，则认为容器正常   
        path: / #URI地址   
        port: 80   
        #host: 127.0.0.1 #主机地址   
        scheme: HTTP   
      initialDelaySeconds: 180 #表明第一次检测在容器启动后多长时间后开始   
      timeoutSeconds: 5 #检测的超时时间   
      periodSeconds: 15  #检查间隔时间   
      #也可以用这种方法   
      #exec: 执行命令的方法进行监测，如果其退出码不为0，则认为容器正常   
      #  command:   
      #    - cat   
      #    - /tmp/health   
      #也可以用这种方法   
      #tcpSocket: //通过tcpSocket检查健康    
      #  port: number    
    lifecycle: #生命周期管理   
      postStart: #容器运行之前运行的任务   
        exec:   
          command:   
            - 'sh'   
            - 'yum upgrade -y'   
      preStop:#容器关闭之前运行的任务   
        exec:   
          command: ['service httpd stop']   
    volumeMounts:  #挂载持久存储卷
    - name: volume #挂载设备的名字，与volumes[*].name 需要对应     
      mountPath: /data #挂载到容器的某个路径下   
      readOnly: True   
  volumes: #定义一组挂载设备   
  - name: volume #定义一个挂载设备的名字   
    #meptyDir: {}   
    hostPath:   
      path: /opt #挂载设备类型为hostPath，路径为宿主机下的/opt,这里设备类型支持很多种
    #nfs
```

```
# yaml格式的pod定义文件完整内容：
apiVersion: v1       #必选，版本号，例如v1
kind: Pod       #必选，Pod
metadata:       #必选，元数据
  name: string       #必选，Pod名称
  namespace: string    #必选，Pod所属的命名空间
  labels:      #自定义标签
    - name: string     #自定义标签名字
  annotations:       #自定义注释列表
    - name: string
spec:         #必选，Pod中容器的详细定义
  containers:      #必选，Pod中容器列表
  - name: string     #必选，容器名称
    image: string    #必选，容器的镜像名称
    imagePullPolicy: [Always | Never | IfNotPresent] #获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像，否则下载镜像，Nerver表示仅使用本地镜像
    command: [string]    #容器的启动命令列表，如不指定，使用打包时使用的启动命令
    args: [string]     #容器的启动命令参数列表
    workingDir: string     #容器的工作目录
    volumeMounts:    #挂载到容器内部的存储卷配置
    - name: string     #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名
      mountPath: string    #存储卷在容器内mount的绝对路径，应少于512字符
      readOnly: boolean    #是否为只读模式
    ports:       #需要暴露的端口库号列表
    - name: string     #端口号名称
      containerPort: int   #容器需要监听的端口号
      hostPort: int    #容器所在主机需要监听的端口号，默认与Container相同
      protocol: string     #端口协议，支持TCP和UDP，默认TCP
    env:       #容器运行前需设置的环境变量列表
    - name: string     #环境变量名称
      value: string    #环境变量的值
    resources:       #资源限制和请求的设置
      limits:      #资源限制的设置
        cpu: string    #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数
        memory: string     #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数
      requests:      #资源请求的设置
        cpu: string    #Cpu请求，容器启动的初始可用数量
        memory: string     #内存清楚，容器启动的初始可用数量
    livenessProbe:     #对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可
      exec:      #对Pod容器内检查方式设置为exec方式
        command: [string]  #exec方式需要制定的命令或脚本
      httpGet:       #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port
        path: string
        port: number
        host: string
        scheme: string
        HttpHeaders:
        - name: string
          value: string
      tcpSocket:     #对Pod内个容器健康检查方式设置为tcpSocket方式
         port: number
       initialDelaySeconds: 0  #容器启动完成后首次探测的时间，单位为秒
       timeoutSeconds: 0   #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒
       periodSeconds: 0    #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次
       successThreshold: 0
       failureThreshold: 0
       securityContext:
         privileged:false
    restartPolicy: [Always | Never | OnFailure]#Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod
    nodeSelector: obeject  #设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定
    imagePullSecrets:    #Pull镜像时使用的secret名称，以key：secretkey格式指定
    - name: string
    hostNetwork:false      #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络
    volumes:       #在该pod上定义共享存储卷列表
    - name: string     #共享存储卷名称 （volumes类型有很多种）
      emptyDir: {}     #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值
      hostPath: string     #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录
        path: string     #Pod所在宿主机的目录，将被用于同期中mount的目录
      secret:      #类型为secret的存储卷，挂载集群与定义的secre对象到容器内部
        scretname: string  
        items:     
        - key: string
          path: string
      configMap:     #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部
        name: string
        items:
        - key: string
```

------

## K8s部署

### 踩坑

* k8s默认会从远端拉取镜像，其配置参数imagePullPolicy为Always。所以，如果yaml文件中没有定义那就是使用默认的，因此我们可以通过将该参数显示设置为Never或者IfNotPresent，k8s就会从本地拉取镜像了
* Helm用来管理资源，要删除需要在这个里面删除，如果没删干净，需要去对象浏览器中删除
* Config可以用来构造环境变量，也可以拷贝文件到Pod中
* 更新ConfigMap后，使用该ConfigMap挂载的Env不会同步更新
* 使用该ConfigMap挂载的Volume中的数据需要一段时间(10s左右)才能同步更新
* StorageClass: "alicloud-disk-efficiency" 是指定存储卷

*   存储卷声明PVC是限制存储卷是使用，存储卷是PV划分资源
*   云盘存储卷是额外的资源，需要单独购买

拉取helm配置：

```
[root@master1 consul]# kubectl create ns consul
[root@master1 consul]# helm fetch stable/consul
[root@master1 consul]# tar zxvf consul
[root@master1 consul]# vim consul/values.yam
```

* K8s持久化存储
* 动态创建存储卷
* Ingress可以访问外网
* 证书相关：
* api server的地址可以在 
* kubectl cluster-info：查看集群信息
* jenkins迁移k8s只用复制部分文件夹即可
  * 会报错config.xml，删除矩阵验证相关
  * 报错插件，挨个安装就好
  * 恢复部分样式
  * 创建jenkins用户的私钥
  * 配置jenkins k8s相关的配置，配置pod存活时间
* K8S命令使用

### jenkins添加K8s slave

* 参考：

命名空间下证书：

* jenkins链接需要填写：

* K8s集群外搭建指南：
* [https://www.qikqiak.com/k8s-book/docs/36.Jenkins%20Slave.html](https://www.qikqiak.com/k8s-book/docs/36.Jenkins%20Slave.html)
* 云盘与nas的存储选择

------

## K8s命令使用

查看pod调度节点及pod_ip

* $ kubectl -n demo get pods -o wide

查看完整的yaml

* $ kubectl -n demo get po myblog -o yaml

查看pod的明细信息及事件

* $ kubectl -n demo describe pod myblog

更新服务版本

* $ kubectl apply -f demo-pod.yaml

删除Pod服务

* 根据文件删除
  * $ kubectl delete -f demo-pod.yaml

* 根据pod_name删除
  * $ kubectl -n <namespace> delete pod <pod_name>

若存在旧的同名服务，先删除掉，后创建 

* $ kubectl -n demo delete pod myblog
* 创建 
* $ kubectl create -f pod-with-volume.yaml

------

## K8s健康检查

检测容器服务是否健康的手段，若不健康，会根据设置的重启策略（restartPolicy）进行操作

两种检测机制可以分别单独设置，若不设置，默认认为Pod是健康的。

#### LivenessProbe探针

* 用于判断容器是否存活，即Pod是否为running状态，如果LivenessProbe探针探测到容器不健康，则kubelet将kill掉容器，并根据容器的重启策略是否重启，如果一个容器不包含LivenessProbe探针，则Kubelet认为容器的LivenessProbe探针的返回值永远成功

#### ReadinessProbe探针

* 用于判断容器是否正常提供服务，即容器的Ready是否为True，是否可以接收请求，如果ReadinessProbe探测失败，则容器的Ready将为False，控制器将此Pod的Endpoint从对应的service的Endpoint列表中移除，从此不再将任何请求调度此Pod上，直到下次探测成功。（剔除此pod不参与接收请求不会将流量转发给此Pod）。

RBAC模式引入了4个资源：

Role，角色

一个Role只能授权访问单个namespace

ClusterRole

一个ClusterRole能够授予和Role一样的权限，但是它是集群范围内的。

Rolebinding

将role中定义的权限分配给用户和用户组。RoleBinding包含主题（users,groups,或service accounts）和授予角色的引用

对于namespace内的授权使用RoleBinding，集群范围内使用ClusterRoleBinding。

基于角色的访问控制：[https://jimmysong.io/kubernetes-handbook/concepts/rbac.html](https://jimmysong.io/kubernetes-handbook/concepts/rbac.html)

bash -c cat：可以直接利用启用容器，来使用命令:

* 是容器不会直接关闭，导致同期退出的话，就pod会通知容器创建失败
* 容器不能关闭

docker tty：使用伪终端调试：[https://qastack.cn/programming/30137135/confused-about-docker-t-option-to-allocate-a-pseudo-tty](https://qastack.cn/programming/30137135/confused-about-docker-t-option-to-allocate-a-pseudo-tty)

进入到pod指定容器：kubectl exec -it my-pod --container main-app -- /bin/bash

---

pod描述：

```
状态值           描述
Pending         API Server已经创建该Pod，但在Pod内还有一个或多个容器的镜像没有创建，包括正在下载镜像的过程。
Runnung         Pod内所有容器均已创建，且至少有一个容器处于运行状态、正在启动状态或正在重启状态。
Succeeded       Pod内所有容器均成功执行后退出，且不会再重启。
Failed          Pod内所有容器均已退出，但至少有一个容器退出为失败状态。
Unknown         由于某种原因无法获取该Pod的状态，可能由于网络通信不畅导致。
```

[https://www.cnblogs.com/mcsiberiawolf/p/12220865.html](https://www.cnblogs.com/mcsiberiawolf/p/12220865.html)

类似于  data-consul-0 的存储声明可以直接在磁盘上划分路径;；但是挂载的文件需要注意权限，去容器组里查看，权限可能不够

k8s 设置  ClusterIP，那么可以通过集群ip，访问每个pod（如果设置这个），内部端点是相同namespace内部访问用的，可以直接用域名来访问

服务名+命名空间的格式，如果是相同的namespace，可以直接使用服务名来解析。 ping redis-master.cx-proxy

hostNetwork: true# 声明pod的网络模式为host模式，效果通docker run --net=host

helm安装稳定的存储库

helm repo add stable [https://charts.helm.sh/stable](https://charts.helm.sh/stable)

搭建helm私有仓库

------

