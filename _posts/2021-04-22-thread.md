---
layout: post
title:  线程池
categories: C++
description: linux线程池
keywords: c++, thread
---
## 线程

### 线程池介绍

进程是管理资源的单位，线程是CPU调度基本单位

#### 创建线程

```
#include <pthread.h>
int pthread_create(pthread_t *thread, const pthread_attr_t *attr,
                    void *(*start_routine) (void *), void *arg);
```

* thread ： 线程ID，
* attr： 线程的一些属性，这些属性包括很多东西，比如线程的调度策略，线程的优先级，线程栈的大小，…
    * 线程结束后，detach状态线程会结束，资源释放
    * joinable状态资源没有被释放

* void *(*start_routine) (void *arg)：它是线程执行函数的回调。
* arg：传递给线程函数的参数

为什么需要多线程

* 多核CPU并发编程
* 防止线程阻塞
* 计算密集型任务，可以放在一个单独线程去执行

SCHED_FIFO, SCHED_RR：可以设置线程的优先级。

默认是SCHED_OTHER：此时不能设置线程的优先级

非分离属性：

* 就是子线程和主线程还有关系，这个关系体现在子线程的销毁上，主线程一定要调用pthread_join去销毁这个线程，joinable状态

分离：

* 线程创建的时候和主线程没有任何关系，线程退出，线程资源就被销毁，detach状态

CPU的亲缘性设置（ affinity）：将进程绑定到指定CPU上，防止进程在处理器之间频繁迁移，来提高应用程序效率

* 线程设置在CPU上执行的时候：CPU缓存，经常访问到的资源(变量)缓存CPU缓存(L1，L2，L3)，高并发网络IO，cash line：64

```
//线程与CPU绑定
int pthread_setaffinity_np(pthread_t thread, size_t cpusetsize,
                                  const cpu_set_t *cpuset);
int pthread_getaffinity_np(pthread_t thread, size_t cpusetsize,
                                  cpu_set_t *cpuset);
sched_getcpu()：获取CPU的数量
```

---

栈属性：

* 默认线程栈的大小只有1M，可以调整

```
int pthread_attr_setstack(pthread_attr_t *attr,
                                 void *stackaddr, size_t stacksize);
int pthread_attr_getstack(const pthread_attr_t *attr,
                                 void **stackaddr, size_t *stacksize);
```

* 线程私有数据(TSD)
    * 线程私有的全局变量，仅在当前线程有效，但是可以跨多个函数访问
    * 线程级别的全局变量

* 栈溢出保护区
* 线程的竞争范围

---

#### 线程与进程区别

* 调度代价低
* 共享资源，便利与用户开发
* 进程的资源是独立的，如果出现了段错误或者其它的致命错误，线程的方式会导致整个进程退出，也就是多个线程都会退出；但是多进程实现，只会影响一个进程
* 多线程处理并发相当困难

------

### 线程池

#### 线程池

* 为了并行开发，利用多CPU的优势

线程池如何设计：

* 生产者与消费者关系
* 有线程去生产任务， 有线程去消费任务

#### 线程池如何设计

两种设计方式：

---

##### 生产者消费者模型，任务队列方式：

1. 将任务放到队列里，线程自己挨个去拿(考虑线程同步)

![.png](\images\posts\thread\2.png)

线程池结构：

缺点：不支持多线程下访问

```
typedef struct queue
{
    int header;
    int tail;
    int size;
    int capcity;
    void **_buf;
} queue_t;
```

buf他是一个动态的数组，header是读指针，tail是写指针

如果采用链表，需要经常去malloc和free（链表的节点）

多线程线程池：

```
typedef struct async_queue
{
    pthread_mutex_t  mutex;
    pthread_cond_t   cond;
    int              waiting_threads;
    queue_t*         queue;
    int              quit;   // 0 表示不退出  1 表示退出
    /* 调试变量 */
    long long        tasked;  // 已经处理完的任务数量
} async_queue_t;
```

pthread_cond_t   cond;   条件变量

* int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex);
  * 参数1：条件变量  参数2：互斥锁

* 等待某个条件满足
  * pthread_mutex_lock(mutex);

cond就是一个信号，

1. 条件是否满足，
2. 如果不满足，则解锁mutex
3. 然后等待cond信号，   挂起了

---

第二种线程池设计方案： 

##### eventfd + epoll

* eventfd，他是由内核实现的线程和进程之间通信的一种方案
* 8个字节内存，初始值就是initval，0,1，任意值。flags

可以在某个地方去write，也可以在另一个地方去read这个数据。

write：在eventfd的现有的值上面 加上这个写入的值，追加写。

read : 就是把这个值读出来，读完后内核对应的值就变成了初始值

eventfd就是内核维护的一个计数器而已。

int eventfd(unsigned int initval, int flags);

从队列里去任务：

epoll_wait因为我们在插入任务的时候写入了数据，所以会返回

1.  async_queue_create：
2.  async_queue_push_tail的时候，我就往这个eventfd里写入1。  > 1，插入了多个任务，
3.  async_queue_pop_head的时候，就read这个eventfd，返回一个task。read只触发一次，返回一个任务

---

第三种设计方案：

##### 将任务指派给指定线程，线程都在执行循环

![-1.png](\images\posts\thread\-1.png)

---

第四种方案：

##### LOK-FREE + 线程死循环

------

### 线程同步

线程同步方式：5 种，以及一些基于它们设计出的锁

#### Mutex（互斥锁）:

* pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER
* pthread_mutex_lock
* xxx ooo
* pthread_mutex_unlock

* Mutex用法不当
  * 重复加锁的会导致死锁
  * 两个线程各自持有一把锁，都在相互等对方释放所持有的锁，此时，两个线程都没有办法执行下去

* 等待队列：
  * 如果没有请求到锁，那么就把该线程放入等待队列里，挂起整个线程的执行
  * 如果持有锁的线程执行完且释放锁，则会唤醒等待队列里的某个线程去执行，那么它就能获取到锁

* 并行开发：
  * 活锁
  * 锁的护航

#### 自旋锁

* 一直处于一种忙的状态，相对于Mutex
* 很简单可以自己实现
  * state == 0; 没有锁住的状态 ==1 锁住的状态

```
while(state !=0 )
{
sched_yield()
}
```

#### CAS （比较与交换，Compare and swap）

* 原子操作
* 是一种有名的无锁算法
* 在任意时刻有且仅有一个线程可以修改某个变量的操作是成功的(合法的)，其余线程都会返回失败（只能等待）
* 实现原理：（硬件支撑）
  * CPU --- 内存 之间通过总线通信，如果cpu对某个变量进行操作，那么它在操作之前会尝试锁住这个总线(LOCK) 
  * CPU 它会把一些常用的变量缓存在CPU的缓存里，锁住这些缓存

#### 条件变量：

#### 信号量

#### barrier （内存栅栏）:

* pthread_barrie_wait
* java CountDownLatch-线程并发的发令枪